[오늘의 내용은 paging기법을 기본으로 사용한다고 가정]

[Demand Paging]
요청이 있으면 메모리를 페이지에 올리는 것.

최초에는 page table이 다 비어있고 invalid였다가 필요에 따라서 vaild가 되고 page table에 올라오는 것임.
그림에서 G, H는 사용하지 않는 페이지다. 그래서 page table에도 없고 invalid되어있다.
B,D,E는 사용하는 페이지 이나, 물리적인 메모리에 올라가 있지 않고 swap area(backing store)에 있다. => swap area에 있는 페이지를 사용하려고 하면 "page fault"가 발생. => 운영체제가 fault난 페이지를 메모리에 올린다.

[page fault]
요청한 페이지가 메모리에 없는 경우 난다. -> 운영체제가 관여함.

- 과정

1. 필요한 페이지를 참조하려고 봤더니 invaild
2. 메모리에 안 올라온 것을 확인하고 MMU가 trap을 발생, (page fault trap) CPU가 운영체제(kernel mode)에게 넘아감
3. 운영체제가 backing store에서 페이지를 가져옴.
4. 그 페이지를 물리 메모리에 올려 놓는다. => 빈 공간(free frame)이 없으면 다른 페이지를 쫓아내고 올려둠(page replacement)
5. page table에 다시 올려두고 vaild로 변경
6. 나중에 CPU를 얻으면 다시 정상적으로 페이지를 얻어 사용 가능하게 됨.

[free frame이 없는 경우]

- page replacement : 어떤 frame을 뺏을지 결정해야 함. => 운영체제가 함. => Replacement Algorithm이 함.(page-fault rate를 최소화하는 것이 목표)

[Replacement 종류]

1. Global Replacement
   replace시 다른 프로세스의 frame을 뺏앗아 올 수 있음 => 많은 페이지가 필요할 경우 빠르게 동작할 수 있다는 장점이 있지만, 독식할 수도 있다는 단점.
2. Local Replacement
   자신에게 할당된 frame만 사용 가능

[Replacement Algorithm]

- Optimal Algorithm(Offlline algorithm)
  가장 먼 미래에 참조되는 page를 replace
  미래를 예측할 수 없으니 실제로는 사용이 되지 않는다.

- FIFO(First In First out) Algorithm
  메모리에 먼저 들어온 page를 먼저 쫓아냄.

- LRU(Least Recently Used) Algorithm
  가장 오래 전에 참조된 page를 지움.

- LFU(Least Frequently Used) Algorithm
  가장 참조가 적은 page를 지움.
  참조가 적은 page가 여러개 있는 경우 => 가장 오래 참조된 page를 지움.

- LRU VS LFU
  LRU 구현 : Linked list로 구현. 아래쪽일 수록 최근. 가장 윗쪽에 있는 애를 쫓아냄. => 시간 복잡도 O(1) (다른 애들과 비교할 필요없으니까)
  LFU 구현 : Heap으로 구현. 내가 참조를 받으면 밑에와 자리를 바꿈 => 시간 복잡도 O(log n) \*중요
  LRU, LFU 사용이 실제로는 불가능하다. why? 이미 물리적인 메모리에 올라와 있는 페이지를 논리적인 메모리가 page table에서 참조하여 사용하려고한다. 이때는 하드웨어적으로 이미 해결이 된다. **즉, 운영체제가 개입을 전혀하지 않음!** 그래서 물리적 메모리에 있는 페이지에 대해선 LRU에 참조 됬다고 가장 아래쪽에 내리지도 못하고 LFU참조 됬다고 횟수를 셀 수 가 없다. => 실제로는 Clock Algorithm을 사용

- Clock Algorithm(Second chance Algorithm, NUR(Not Used Recently), NRU(Not Recently Used))
  frame당 reference bit이 하나씩 존재.
  reference bit(access bit)가 1이면 최근에 사용된 페이지고 0이면 최근에 사용이 안된 페이지다. reference bit은 그 페이지가 사용이되면 자동으로 1이 된다. => 이건 운영체제가 하는게 아니고 하드웨어가 동작.
  운영체제가 만약 자리가 없어서 하나의 page를 쫓아내야한다. 그래서 하나씩 페이지를 돈다. 만약 reference bit가 1이면 최근에 사용된 것이므로 0으로 바꿔놓고 다음 페이지를 또 확인한다. 이렇게 하다가 reference bit가 0인 애를 발견하면 그 페이지를 쫓아낸다.
  bit의 1과 0의 의미가 왜 중요한가? 저건 시계저처럼 모든 것을 한 바퀴를 돌아가면서 1인건 0으로 바꾸면서 다음 꺼를 빼기 위해 돌아간다. 그렇게 한 바퀴가 돌아가는 동안에 또 1이 되어있다는 것은 그 동안에 그 페이지를 사용했다는 것이므로
  0으로 되어있다는 것은 한 바퀴 돌아가는 동안에 사용이 안됬다는 것이므로 쫓아내기에 적합하다.
  modified bit(dirty bit) 쓰기가 발생 했을 때 1이 됨. 이게 왜 필요할까? 메모리에 올라와있는 것에 쓰기가 발생하면 데이터가 변경된다. 그런데 이때 만약 이 page가 지워지게 된다면 변경된 data까지 날아간다. 그래서 만약 modified bit을 확인해서 1이라면, 디스크에 변경된 데이터를 저장하고 쫓아낸다. (disk에 자주 접근하면 속도가 느려지기 때문에 변경된 데이터가 있더라도 메모리에 올려놓았다가 나중에 모아서 disk에 저장 처리를 한다.)
  읽기만 발생했을 때, reference bit을 1로 만듬
  쓰기가 발생했을 때, reference bit과 modified bit을 1로 만듬.

[Page Frame의 Allocation]
각 프로세스마다 Frame의 크기를 미리 할당 시킴.
Allocation의 왜 필요할까? 만약 하나의 프로세스가 loop를 돌 때 5개의 페이지가 필요하다고 가정해보자. 만약 프로세스가 페이지 Frame을 3개만 받았다면 계속 page fault가 일어날 것이다. 그래서 각 프로그램마다 메모리 공간을 최소한 Allocation시켜야한다.
종류
a. Equlal Allocation
b. Proportional Allocation
c. Priority Allocation

[Thrashing]
메모리에 프로그램 갯수가 늘수록 CPU이용률도 높아진다. 그러나 메모리에 너무 많은 프로그램 갯수가 올라가면 어느 순간 CPU이용률 뚝 떨이진다. 이것을 thrashing이 일어났다라고 한다.
thrashing이란? 메모리에 너무 많은 프로그램을 올려두어서, 프로그램이 돌아가기 위해 필요한 최소한의 메모리를 얻지 못해서 생기는 문제이다. => 해결 : Working-Set Model

[Working-Set Model]
Locality set은 프로세스가 집중적으로 참조하는 page들의 집합을 의미한다.
Working set 역시 Locality set과 비슷한 의미로, 프로세스가 원할히 수행 되기 위해 한꺼번에 메모리에 올라와 있어야하는 page들의 집합을 의미한다.
Working-Set Model은 Working set 전체가 메모리에 올라와있어야만 프로세스가 수행되고 그렇지 않을 경우 모든 frame을 반납 후 swap out된다. => Thrashing이 방지 됨.

- Working-Set Algorithm : Working set은 정해저 있는게 아니고 과거의 데이터로 추측해서 집합을 만드는 것임. 예를 들어, 현재 시점부터 과거의 n개까지의 사용된 페이지를 모아 Working set으로 간주 하는 것이다.

[캐슁 기법]

- 한정된 빠른 공간(=캐쉬)에 요청된 데이터를 저장해 두었다가 후속 요청시 캐쉬로부터 직접 서비스하는 방식 ex)물리메모리(캐쉬)와 blocking store
- 다양한 예 : paging system, cache memory, buffer caching, Web chaching
